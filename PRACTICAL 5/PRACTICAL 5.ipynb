{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hbhak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "# If nltk stop word is not downloaded\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my name is Harsh.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harsh is too lazy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He is too cool.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He is studying NLP.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He has brown eyes.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             documents\n",
       "0    my name is Harsh.\n",
       "1   Harsh is too lazy.\n",
       "2      He is too cool.\n",
       "3  He is studying NLP.\n",
       "4   He has brown eyes."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of documents\n",
    "a1 = \"my name is Harsh.\"\n",
    "a2 = \"Harsh is too lazy.\"\n",
    "a3 = \"He is too cool.\"\n",
    "a4 = \"He is studying NLP.\"\n",
    "a5 = \"He has brown eyes.\"\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"documents\"] = [a1,a2,a3,a4,a5]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documents</th>\n",
       "      <th>clean_documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my name is Harsh.</td>\n",
       "      <td>name harsh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harsh is too lazy.</td>\n",
       "      <td>harsh too lazy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He is too cool.</td>\n",
       "      <td>too cool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He is studying NLP.</td>\n",
       "      <td>studying nlp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He has brown eyes.</td>\n",
       "      <td>has brown eyes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             documents clean_documents\n",
       "0    my name is Harsh.      name harsh\n",
       "1   Harsh is too lazy.  harsh too lazy\n",
       "2      He is too cool.        too cool\n",
       "3  He is studying NLP.    studying nlp\n",
       "4   He has brown eyes.  has brown eyes"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing\n",
    "df['clean_documents'] = df['documents'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "df['clean_documents'] = df['clean_documents'].fillna('').apply(lambda x: ' '.join([w for w in x.split() if len(w)>2]))\n",
    "df['clean_documents'] = df['clean_documents'].fillna('').apply(lambda x: x.lower())\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hbhak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('stopwords') \n",
    "from nltk.corpus import stopwords \n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documents</th>\n",
       "      <th>clean_documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my name is Harsh.</td>\n",
       "      <td>name harsh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harsh is too lazy.</td>\n",
       "      <td>harsh lazy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He is too cool.</td>\n",
       "      <td>cool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He is studying NLP.</td>\n",
       "      <td>studying nlp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He has brown eyes.</td>\n",
       "      <td>brown eyes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             documents clean_documents\n",
       "0    my name is Harsh.      name harsh\n",
       "1   Harsh is too lazy.      harsh lazy\n",
       "2      He is too cool.            cool\n",
       "3  He is studying NLP.    studying nlp\n",
       "4   He has brown eyes.      brown eyes"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenization\n",
    "tokenized_doc = df['clean_documents'].fillna('').apply(lambda x: x.split())\n",
    "\n",
    "# remove stop-words\n",
    "\n",
    "#tokenized_doc = tokenized_doc.apply(lambda x: [itemstop_words = stopwords.words('english') for item in x if item not in stop_words])\n",
    "# remove stop-words \n",
    "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words]) \n",
    "# de-tokenization\n",
    "detokenized_doc = []\n",
    "for i in range(len(df)):\n",
    "    t = ' '.join(tokenized_doc[i])\n",
    "    detokenized_doc.append(t)\n",
    "\n",
    "df['clean_documents'] = detokenized_doc\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.62791376, 0.77828292,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.70710678, 0.70710678],\n",
       "       [0.70710678, 0.        , 0.70710678, 0.        , 0.        ,\n",
       "        0.        , 0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF vector\n",
    "vectorizer = TfidfVectorizer(stop_words='english', smooth_idf=True)\n",
    "X = vectorizer.fit_transform(df['clean_documents'])\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape \n",
    "#A56   U(5,5). S()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVD represent documents and terms in vectors \n",
    "svd_model = TruncatedSVD(n_components=2, algorithm='randomized', n_iter=100, random_state=122)\n",
    "lsa = svd_model.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documents</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>name harsh</td>\n",
       "      <td>0.9021955890080026</td>\n",
       "      <td>0.0000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>harsh lazy</td>\n",
       "      <td>0.9021955890080025</td>\n",
       "      <td>-0.0000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cool</td>\n",
       "      <td>0.0000000000000000</td>\n",
       "      <td>-0.0000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>studying nlp</td>\n",
       "      <td>0.0000000000000000</td>\n",
       "      <td>1.0000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brown eyes</td>\n",
       "      <td>0.0000000000000001</td>\n",
       "      <td>-0.0000000000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      documents            topic_1             topic_2\n",
       "0    name harsh 0.9021955890080026  0.0000000000000000\n",
       "1    harsh lazy 0.9021955890080025 -0.0000000000000000\n",
       "2          cool 0.0000000000000000 -0.0000000000000000\n",
       "3  studying nlp 0.0000000000000000  1.0000000000000000\n",
       "4    brown eyes 0.0000000000000001 -0.0000000000000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Documents - Topic vector\n",
    "pd.options.display.float_format = '{:,.16f}'.format\n",
    "topic_encoded_df = pd.DataFrame(lsa, columns = [\"topic_1\", \"topic_2\"])\n",
    "topic_encoded_df[\"documents\"] = df['clean_documents']\n",
    "display(topic_encoded_df[[\"documents\", \"topic_1\", \"topic_2\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brown', 'cool', 'eyes', 'harsh', 'lazy', 'nlp', 'studying']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features or words used as features \n",
    "dictionary = vectorizer.get_feature_names()\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>brown</th>\n",
       "      <td>0.0000000000000001</td>\n",
       "      <td>0.0000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cool</th>\n",
       "      <td>-0.0000000000000000</td>\n",
       "      <td>0.0000000000000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eyes</th>\n",
       "      <td>0.0000000000000001</td>\n",
       "      <td>0.0000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>harsh</th>\n",
       "      <td>0.9021955890080026</td>\n",
       "      <td>0.0000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lazy</th>\n",
       "      <td>0.4313271602559978</td>\n",
       "      <td>-0.0000000000000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nlp</th>\n",
       "      <td>0.0000000000000000</td>\n",
       "      <td>0.7071067811865476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>studying</th>\n",
       "      <td>0.0000000000000000</td>\n",
       "      <td>0.7071067811865476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     topic_1             topic_2\n",
       "brown     0.0000000000000001  0.0000000000000000\n",
       "cool     -0.0000000000000000  0.0000000000000001\n",
       "eyes      0.0000000000000001  0.0000000000000000\n",
       "harsh     0.9021955890080026  0.0000000000000000\n",
       "lazy      0.4313271602559978 -0.0000000000000001\n",
       "nlp       0.0000000000000000  0.7071067811865476\n",
       "studying  0.0000000000000000  0.7071067811865476"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Term-Topic matrix\n",
    "encoding_matrix = pd.DataFrame(svd_model.components_, index = [\"topic_1\",\"topic_2\"], columns = (dictionary)).T\n",
    "encoding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
